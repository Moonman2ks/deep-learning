{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exxon Mobil Corporation\n",
    "\n",
    "### Stock prediction with deep learning\n",
    "\n",
    "<br/> Gytis Kazlauskis KT-8/2\n",
    "<br/> email: gytis.ka8869@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://jumpvine.net/wp-content/uploads/Steps-to-Creating-Company-Culture-e1508926692787.jpg\" width=\"800\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br/><b>1. Data loading and pre-processing</b>\n",
    "<br/>1.1 Importing the main libraries\n",
    "<br/>1.2 Importing the dataset\n",
    "<br/>1.3 Feature scaling\n",
    "<br/>1.4 Splitting the training set to dependent and independent variables\n",
    "<br/>1.5 Reshaping the matrix\n",
    "<br/><b>2. Building the RNN</b>\n",
    "<br/>2.1 RNN initialization\n",
    "<br/>2.2 Adding the first layer\n",
    "<br/>2.3 Adding 5 more layers\n",
    "<br/>2.4 Adding the output layer & compiling\n",
    "<br/><b>3. Train and deploy the RNN</b>\n",
    "<br/>3.1 Fit the RNN to the Training set\n",
    "<br/>3.2 Computing Predictions\n",
    "<br/>3.3 \n",
    "<br/><b>4. Improving the RNN</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data:image/jpeg;base64,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\" width=\"800\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a 10-year history of the Exxon Mobil prices predict the stock values for the period of the recent most month that are not included in the historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the main libraries\n",
    "\n",
    "- [Numpy](http://www.numpy.org): library for the Python programming language\n",
    "- [matplotlib](https://matplotlib.org): a plotting library for the Python programming language and its numerical mathematics extension NumPy.\n",
    "- [pandas](https://pandas.pydata.org): software library written for the Python programming language for data manipulation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the 3 main libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset description: the open high, low and close values of the Exxon Mobil from July 2009 to July 2019.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "\n",
    "# load the file contents \n",
    "dataset_train = pd.read_csv('dataset_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2009-07-30</td>\n",
       "      <td>70.300003</td>\n",
       "      <td>71.519997</td>\n",
       "      <td>69.910004</td>\n",
       "      <td>70.720001</td>\n",
       "      <td>51.192154</td>\n",
       "      <td>37842300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2009-07-31</td>\n",
       "      <td>70.360001</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>69.430000</td>\n",
       "      <td>70.389999</td>\n",
       "      <td>50.953278</td>\n",
       "      <td>28070600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2009-08-03</td>\n",
       "      <td>70.959999</td>\n",
       "      <td>71.400002</td>\n",
       "      <td>70.300003</td>\n",
       "      <td>70.650002</td>\n",
       "      <td>51.141487</td>\n",
       "      <td>24756800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2009-08-04</td>\n",
       "      <td>70.250000</td>\n",
       "      <td>70.639999</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.599998</td>\n",
       "      <td>51.105297</td>\n",
       "      <td>18612000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2009-08-05</td>\n",
       "      <td>70.480003</td>\n",
       "      <td>70.489998</td>\n",
       "      <td>69.610001</td>\n",
       "      <td>70.029999</td>\n",
       "      <td>50.692692</td>\n",
       "      <td>20348800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2009-07-30  70.300003  71.519997  69.910004  70.720001  51.192154  37842300\n",
       "1  2009-07-31  70.360001  70.500000  69.430000  70.389999  50.953278  28070600\n",
       "2  2009-08-03  70.959999  71.400002  70.300003  70.650002  51.141487  24756800\n",
       "3  2009-08-04  70.250000  70.639999  70.000000  70.599998  51.105297  18612000\n",
       "4  2009-08-05  70.480003  70.489998  69.610001  70.029999  50.692692  20348800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subtable of relevant entries (open values)\n",
    "# The .values makes this vector a numpy array\n",
    "training_set = dataset_train.iloc[:, 1:2].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70.300003],\n",
       "       [70.360001],\n",
       "       [70.959999],\n",
       "       ...,\n",
       "       [74.870003],\n",
       "       [74.879997],\n",
       "       [75.059998]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "The next step is to rescale our data to the range from 0 to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "# import the MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scaler instance to rescale all data to the range of 0.0 to 1.0 \n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the actual training set of scaled values\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28274133],\n",
       "       [0.28400259],\n",
       "       [0.29661554],\n",
       "       ...,\n",
       "       [0.37881028],\n",
       "       [0.37902037],\n",
       "       [0.38280429]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the training set to dependent and independent variables\n",
    "Importing data from different sources is fundamental to data science and machine learning. The abundance of good quality data not only eliminates a lot of pre-processing steps but also determines how likely your model is going to succeed in predicting plausible outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "\n",
    "# the 60 stock prices in the last 3 months before today\n",
    "X_train = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2517, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the stock price today\n",
    "y_train = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start from day 120 because that is the first instance allowing us to \n",
    "# go back 120 days\n",
    "for i in range(120, 2517): \n",
    "    # 0 is the column ID, the only column in this case.    \n",
    "    # put the last 120 days values in one row of X_train\n",
    "    X_train.append(training_set_scaled[i-120:i, 0]) \n",
    "    y_train.append(training_set_scaled[i, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28274133, 0.28400259, 0.29661554, ..., 0.26907723, 0.24994745,\n",
       "        0.24616355],\n",
       "       [0.28400259, 0.29661554, 0.28169018, ..., 0.24994745, 0.24616355,\n",
       "        0.23691413],\n",
       "       [0.29661554, 0.28169018, 0.28652523, ..., 0.24616355, 0.23691413,\n",
       "        0.20327936],\n",
       "       ...,\n",
       "       [0.39751953, 0.38532693, 0.39373563, ..., 0.38469632, 0.38974145,\n",
       "        0.3979399 ],\n",
       "       [0.38532693, 0.39373563, 0.38049189, ..., 0.38974145, 0.3979399 ,\n",
       "        0.37881028],\n",
       "       [0.39373563, 0.38049189, 0.35547622, ..., 0.3979399 , 0.37881028,\n",
       "        0.37902037]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the Matrix\n",
    "\n",
    "A new matrix dimension is needed to accommodate the indicator (predictor). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.pixabay.com/photo/2015/03/22/17/34/cubic-684961_1280.jpg\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data matrix, we retain the 2 original dimensions and add a third of depth=1\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN initialization\n",
    "\n",
    "- Import the sequential model from the Keras API;\n",
    "- Import the Dense layer template from the Keras API;\n",
    "- Import the LSTM model from the Keras API\n",
    "- Create an instance of the sequential model called regressor because we want to predict a continuous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the RNN as a sequence of layers\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the first layer\n",
    "\n",
    "<br/>We first add an object of the LSTM /class! \n",
    "<br/><b>Specifications:</b>\n",
    "<br/>100 neurons\n",
    "<br/>return requences = true\n",
    "<br/>input shape : 3D\n",
    "<br/>dropout rate = 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Adding the input layer and the LSTM layer\n",
    "regressor.add(LSTM(units = 100, return_sequences = True, input_shape =  (X_train.shape[1], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# the argument is the dropout rate to ignore in the layers (20%), \n",
    "# i.e. 50 units * 20% = 10 units will be dropped each time\n",
    "regressor.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add More Layers\n",
    "\n",
    "Adding 5 more layers, with 100 neurons and the dropout rate of 20%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "# we removed the return_sequences because we no longer return a \n",
    "# sequence but a value instead\n",
    "regressor.add(LSTM(units = 100))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Output Layer & Compile\n",
    "\n",
    "The output has 1 dimension , i.e. one value to be predicted thus or output fully connected layer has dimensionality = 1.\n",
    "\n",
    "- **Optimizer**: rmsprop\n",
    "- **Loss function**: regression problems take the mean square error as most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and deploy the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the RNN to the Training set\n",
    "\n",
    "RNN is being trained using the data from **Training Set X** and **predictors in y**.\n",
    "<br/>100 iterations will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "2397/2397 [==============================] - 207s 86ms/step - loss: 0.1373\n",
      "Epoch 2/100\n",
      "2397/2397 [==============================] - 203s 85ms/step - loss: 0.0237\n",
      "Epoch 3/100\n",
      "2397/2397 [==============================] - 267s 112ms/step - loss: 0.0142\n",
      "Epoch 4/100\n",
      "2397/2397 [==============================] - 217s 91ms/step - loss: 0.0106\n",
      "Epoch 5/100\n",
      "2397/2397 [==============================] - 219s 91ms/step - loss: 0.0084\n",
      "Epoch 6/100\n",
      "2397/2397 [==============================] - 218s 91ms/step - loss: 0.0073\n",
      "Epoch 7/100\n",
      "2397/2397 [==============================] - 217s 91ms/step - loss: 0.0061\n",
      "Epoch 8/100\n",
      "2397/2397 [==============================] - 219s 91ms/step - loss: 0.0056\n",
      "Epoch 9/100\n",
      "2397/2397 [==============================] - 217s 91ms/step - loss: 0.0052\n",
      "Epoch 10/100\n",
      "2397/2397 [==============================] - 217s 90ms/step - loss: 0.0045\n",
      "Epoch 11/100\n",
      "2397/2397 [==============================] - 219s 92ms/step - loss: 0.0044\n",
      "Epoch 12/100\n",
      "2397/2397 [==============================] - 216s 90ms/step - loss: 0.0041\n",
      "Epoch 13/100\n",
      "2397/2397 [==============================] - 201s 84ms/step - loss: 0.0037\n",
      "Epoch 14/100\n",
      "2397/2397 [==============================] - 210s 88ms/step - loss: 0.0035\n",
      "Epoch 15/100\n",
      "2397/2397 [==============================] - 231s 96ms/step - loss: 0.0035\n",
      "Epoch 16/100\n",
      "2397/2397 [==============================] - 227s 95ms/step - loss: 0.0031\n",
      "Epoch 17/100\n",
      "2397/2397 [==============================] - 228s 95ms/step - loss: 0.0030\n",
      "Epoch 18/100\n",
      "2397/2397 [==============================] - 232s 97ms/step - loss: 0.0030\n",
      "Epoch 19/100\n",
      "2397/2397 [==============================] - 221s 92ms/step - loss: 0.0027\n",
      "Epoch 20/100\n",
      "2397/2397 [==============================] - 233s 97ms/step - loss: 0.0029\n",
      "Epoch 21/100\n",
      "2397/2397 [==============================] - 223s 93ms/step - loss: 0.0028\n",
      "Epoch 22/100\n",
      "2397/2397 [==============================] - 232s 97ms/step - loss: 0.0026\n",
      "Epoch 23/100\n",
      "2397/2397 [==============================] - 203s 85ms/step - loss: 0.0024\n",
      "Epoch 24/100\n",
      "2397/2397 [==============================] - 194s 81ms/step - loss: 0.0027\n",
      "Epoch 25/100\n",
      "2397/2397 [==============================] - 195s 81ms/step - loss: 0.0025\n",
      "Epoch 26/100\n",
      "2397/2397 [==============================] - 248s 104ms/step - loss: 0.0023\n",
      "Epoch 27/100\n",
      "2397/2397 [==============================] - 215s 90ms/step - loss: 0.0024\n",
      "Epoch 28/100\n",
      "2397/2397 [==============================] - 192s 80ms/step - loss: 0.0022\n",
      "Epoch 29/100\n",
      "2397/2397 [==============================] - 190s 79ms/step - loss: 0.0021\n",
      "Epoch 30/100\n",
      "2397/2397 [==============================] - 190s 79ms/step - loss: 0.0021\n",
      "Epoch 31/100\n",
      "2397/2397 [==============================] - 221s 92ms/step - loss: 0.0021\n",
      "Epoch 32/100\n",
      "2397/2397 [==============================] - 226s 94ms/step - loss: 0.0020\n",
      "Epoch 33/100\n",
      "2397/2397 [==============================] - 198s 83ms/step - loss: 0.0020\n",
      "Epoch 34/100\n",
      "2397/2397 [==============================] - 198s 83ms/step - loss: 0.0020\n",
      "Epoch 35/100\n",
      "2397/2397 [==============================] - 223s 93ms/step - loss: 0.0020\n",
      "Epoch 36/100\n",
      "2397/2397 [==============================] - 219s 92ms/step - loss: 0.0020\n",
      "Epoch 37/100\n",
      "2397/2397 [==============================] - 221s 92ms/step - loss: 0.0019\n",
      "Epoch 38/100\n",
      "2397/2397 [==============================] - 220s 92ms/step - loss: 0.0018\n",
      "Epoch 39/100\n",
      "2397/2397 [==============================] - 220s 92ms/step - loss: 0.0018\n",
      "Epoch 40/100\n",
      "2397/2397 [==============================] - 222s 93ms/step - loss: 0.0018\n",
      "Epoch 41/100\n",
      "2397/2397 [==============================] - 222s 93ms/step - loss: 0.0018\n",
      "Epoch 42/100\n",
      "2397/2397 [==============================] - 220s 92ms/step - loss: 0.0018\n",
      "Epoch 43/100\n",
      "2397/2397 [==============================] - 220s 92ms/step - loss: 0.0018\n",
      "Epoch 44/100\n",
      "2397/2397 [==============================] - 220s 92ms/step - loss: 0.0017\n",
      "Epoch 45/100\n",
      "2397/2397 [==============================] - 227s 95ms/step - loss: 0.0018\n",
      "Epoch 46/100\n",
      "2397/2397 [==============================] - 235s 98ms/step - loss: 0.0017\n",
      "Epoch 47/100\n",
      "2397/2397 [==============================] - 230s 96ms/step - loss: 0.0017\n",
      "Epoch 48/100\n",
      "2397/2397 [==============================] - 226s 94ms/step - loss: 0.0017\n",
      "Epoch 49/100\n",
      "2397/2397 [==============================] - 219s 92ms/step - loss: 0.0016\n",
      "Epoch 50/100\n",
      "2397/2397 [==============================] - 219s 91ms/step - loss: 0.0016\n",
      "Epoch 51/100\n",
      "2397/2397 [==============================] - 220s 92ms/step - loss: 0.0015\n",
      "Epoch 52/100\n",
      "2397/2397 [==============================] - 229s 96ms/step - loss: 0.0017\n",
      "Epoch 53/100\n",
      "2397/2397 [==============================] - 230s 96ms/step - loss: 0.0016\n",
      "Epoch 54/100\n",
      "2397/2397 [==============================] - 240s 100ms/step - loss: 0.0015\n",
      "Epoch 55/100\n",
      "2397/2397 [==============================] - 229s 95ms/step - loss: 0.0016\n",
      "Epoch 56/100\n",
      "2397/2397 [==============================] - 213s 89ms/step - loss: 0.0015\n",
      "Epoch 57/100\n",
      "2397/2397 [==============================] - 212s 89ms/step - loss: 0.0015\n",
      "Epoch 58/100\n",
      "2397/2397 [==============================] - 213s 89ms/step - loss: 0.0016\n",
      "Epoch 59/100\n",
      "2397/2397 [==============================] - 213s 89ms/step - loss: 0.0015\n",
      "Epoch 60/100\n",
      "2397/2397 [==============================] - 207s 86ms/step - loss: 0.0016\n",
      "Epoch 61/100\n",
      "2397/2397 [==============================] - 207s 86ms/step - loss: 0.0015\n",
      "Epoch 62/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0015\n",
      "Epoch 63/100\n",
      "2397/2397 [==============================] - 207s 86ms/step - loss: 0.0015\n",
      "Epoch 64/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0015\n",
      "Epoch 65/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0013\n",
      "Epoch 66/100\n",
      "2397/2397 [==============================] - 207s 86ms/step - loss: 0.0014\n",
      "Epoch 67/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0015\n",
      "Epoch 68/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0014\n",
      "Epoch 69/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0013\n",
      "Epoch 70/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0013\n",
      "Epoch 71/100\n",
      "2397/2397 [==============================] - 210s 88ms/step - loss: 0.0014\n",
      "Epoch 72/100\n",
      "2397/2397 [==============================] - 207s 86ms/step - loss: 0.0013\n",
      "Epoch 73/100\n",
      "2397/2397 [==============================] - 207s 86ms/step - loss: 0.0014\n",
      "Epoch 74/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0013\n",
      "Epoch 75/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0014\n",
      "Epoch 76/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0012\n",
      "Epoch 77/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0013\n",
      "Epoch 78/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0013\n",
      "Epoch 79/100\n",
      "2397/2397 [==============================] - 205s 86ms/step - loss: 0.0013\n",
      "Epoch 80/100\n",
      "2397/2397 [==============================] - 205s 86ms/step - loss: 0.0013\n",
      "Epoch 81/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0013\n",
      "Epoch 82/100\n",
      "2397/2397 [==============================] - 205s 86ms/step - loss: 0.0012\n",
      "Epoch 83/100\n",
      "2397/2397 [==============================] - 205s 86ms/step - loss: 0.0012\n",
      "Epoch 84/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0012\n",
      "Epoch 85/100\n",
      "2397/2397 [==============================] - 205s 86ms/step - loss: 0.0012\n",
      "Epoch 86/100\n",
      "2397/2397 [==============================] - 207s 86ms/step - loss: 0.0012\n",
      "Epoch 87/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0013\n",
      "Epoch 88/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0012\n",
      "Epoch 89/100\n",
      "2397/2397 [==============================] - 207s 86ms/step - loss: 0.0012\n",
      "Epoch 90/100\n",
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0012\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2397/2397 [==============================] - 206s 86ms/step - loss: 0.0011\n",
      "Epoch 92/100\n",
      "2397/2397 [==============================] - 205s 86ms/step - loss: 0.0012\n",
      "Epoch 93/100\n",
      "2397/2397 [==============================] - 205s 85ms/step - loss: 0.0012\n",
      "Epoch 94/100\n",
      "2397/2397 [==============================] - 205s 85ms/step - loss: 0.0012\n",
      "Epoch 95/100\n",
      "2397/2397 [==============================] - 204s 85ms/step - loss: 0.0011\n",
      "Epoch 96/100\n",
      "2397/2397 [==============================] - 205s 86ms/step - loss: 0.0012\n",
      "Epoch 97/100\n",
      "2397/2397 [==============================] - 204s 85ms/step - loss: 0.0010\n",
      "Epoch 98/100\n",
      "2397/2397 [==============================] - 204s 85ms/step - loss: 0.0011\n",
      "Epoch 99/100\n",
      "2397/2397 [==============================] - 204s 85ms/step - loss: 0.0011\n",
      "Epoch 100/100\n",
      "2397/2397 [==============================] - 205s 85ms/step - loss: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb0784f7780>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Predictions\n",
    "\n",
    "Create a data-frame by importing the Exxon Stock Price Test set for August 2019 using pandas and make it a numpy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>75.040001</td>\n",
       "      <td>75.660004</td>\n",
       "      <td>74.260002</td>\n",
       "      <td>74.360001</td>\n",
       "      <td>73.446770</td>\n",
       "      <td>13104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>73.739998</td>\n",
       "      <td>74.269997</td>\n",
       "      <td>72.269997</td>\n",
       "      <td>72.459999</td>\n",
       "      <td>71.570107</td>\n",
       "      <td>17132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>72.610001</td>\n",
       "      <td>73.260002</td>\n",
       "      <td>71.180000</td>\n",
       "      <td>71.750000</td>\n",
       "      <td>70.868828</td>\n",
       "      <td>21376700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>70.779999</td>\n",
       "      <td>70.919998</td>\n",
       "      <td>69.610001</td>\n",
       "      <td>70.279999</td>\n",
       "      <td>69.416878</td>\n",
       "      <td>19080900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>70.290001</td>\n",
       "      <td>71.010002</td>\n",
       "      <td>70.279999</td>\n",
       "      <td>70.959999</td>\n",
       "      <td>70.088524</td>\n",
       "      <td>12282400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>69.860001</td>\n",
       "      <td>70.879997</td>\n",
       "      <td>69.400002</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>69.634178</td>\n",
       "      <td>15231100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>70.849998</td>\n",
       "      <td>72.410004</td>\n",
       "      <td>70.620003</td>\n",
       "      <td>72.379997</td>\n",
       "      <td>71.491089</td>\n",
       "      <td>14304100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>72.129997</td>\n",
       "      <td>72.250000</td>\n",
       "      <td>70.470001</td>\n",
       "      <td>70.839996</td>\n",
       "      <td>69.970001</td>\n",
       "      <td>13686600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>70.059998</td>\n",
       "      <td>70.160004</td>\n",
       "      <td>69.330002</td>\n",
       "      <td>69.629997</td>\n",
       "      <td>69.629997</td>\n",
       "      <td>8668400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>69.269997</td>\n",
       "      <td>70.620003</td>\n",
       "      <td>68.919998</td>\n",
       "      <td>70.489998</td>\n",
       "      <td>70.489998</td>\n",
       "      <td>12403300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>69.070000</td>\n",
       "      <td>69.089996</td>\n",
       "      <td>67.650002</td>\n",
       "      <td>67.650002</td>\n",
       "      <td>67.650002</td>\n",
       "      <td>18114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>67.459999</td>\n",
       "      <td>67.559998</td>\n",
       "      <td>66.529999</td>\n",
       "      <td>67.250000</td>\n",
       "      <td>67.250000</td>\n",
       "      <td>12874400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>67.779999</td>\n",
       "      <td>68.459999</td>\n",
       "      <td>67.269997</td>\n",
       "      <td>68.300003</td>\n",
       "      <td>68.300003</td>\n",
       "      <td>12649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>69.650002</td>\n",
       "      <td>68.860001</td>\n",
       "      <td>69.449997</td>\n",
       "      <td>69.449997</td>\n",
       "      <td>10032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>69.300003</td>\n",
       "      <td>69.300003</td>\n",
       "      <td>68.709999</td>\n",
       "      <td>69.029999</td>\n",
       "      <td>69.029999</td>\n",
       "      <td>9743500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>69.959999</td>\n",
       "      <td>69.980003</td>\n",
       "      <td>69.370003</td>\n",
       "      <td>69.720001</td>\n",
       "      <td>69.720001</td>\n",
       "      <td>10134200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>69.910004</td>\n",
       "      <td>69.959999</td>\n",
       "      <td>69.250000</td>\n",
       "      <td>69.570000</td>\n",
       "      <td>69.570000</td>\n",
       "      <td>8972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>68.820000</td>\n",
       "      <td>69.529999</td>\n",
       "      <td>67.029999</td>\n",
       "      <td>67.489998</td>\n",
       "      <td>67.489998</td>\n",
       "      <td>15371900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>68.120003</td>\n",
       "      <td>68.260002</td>\n",
       "      <td>67.529999</td>\n",
       "      <td>67.849998</td>\n",
       "      <td>67.849998</td>\n",
       "      <td>7343900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>68.129997</td>\n",
       "      <td>68.440002</td>\n",
       "      <td>66.970001</td>\n",
       "      <td>67.190002</td>\n",
       "      <td>67.190002</td>\n",
       "      <td>9490900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>67.529999</td>\n",
       "      <td>67.980003</td>\n",
       "      <td>67.160004</td>\n",
       "      <td>67.680000</td>\n",
       "      <td>67.680000</td>\n",
       "      <td>9647400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>68.300003</td>\n",
       "      <td>68.669998</td>\n",
       "      <td>68.089996</td>\n",
       "      <td>68.430000</td>\n",
       "      <td>68.430000</td>\n",
       "      <td>9004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>68.610001</td>\n",
       "      <td>69.080002</td>\n",
       "      <td>68.059998</td>\n",
       "      <td>68.480003</td>\n",
       "      <td>68.480003</td>\n",
       "      <td>9180800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date       Open       High        Low      Close  Adj Close  \\\n",
       "0   2019-07-31  75.040001  75.660004  74.260002  74.360001  73.446770   \n",
       "1   2019-08-01  73.739998  74.269997  72.269997  72.459999  71.570107   \n",
       "2   2019-08-02  72.610001  73.260002  71.180000  71.750000  70.868828   \n",
       "3   2019-08-05  70.779999  70.919998  69.610001  70.279999  69.416878   \n",
       "4   2019-08-06  70.290001  71.010002  70.279999  70.959999  70.088524   \n",
       "5   2019-08-07  69.860001  70.879997  69.400002  70.500000  69.634178   \n",
       "6   2019-08-08  70.849998  72.410004  70.620003  72.379997  71.491089   \n",
       "7   2019-08-09  72.129997  72.250000  70.470001  70.839996  69.970001   \n",
       "8   2019-08-12  70.059998  70.160004  69.330002  69.629997  69.629997   \n",
       "9   2019-08-13  69.269997  70.620003  68.919998  70.489998  70.489998   \n",
       "10  2019-08-14  69.070000  69.089996  67.650002  67.650002  67.650002   \n",
       "11  2019-08-15  67.459999  67.559998  66.529999  67.250000  67.250000   \n",
       "12  2019-08-16  67.779999  68.459999  67.269997  68.300003  68.300003   \n",
       "13  2019-08-19  68.970001  69.650002  68.860001  69.449997  69.449997   \n",
       "14  2019-08-20  69.300003  69.300003  68.709999  69.029999  69.029999   \n",
       "15  2019-08-21  69.959999  69.980003  69.370003  69.720001  69.720001   \n",
       "16  2019-08-22  69.910004  69.959999  69.250000  69.570000  69.570000   \n",
       "17  2019-08-23  68.820000  69.529999  67.029999  67.489998  67.489998   \n",
       "18  2019-08-26  68.120003  68.260002  67.529999  67.849998  67.849998   \n",
       "19  2019-08-27  68.129997  68.440002  66.970001  67.190002  67.190002   \n",
       "20  2019-08-28  67.529999  67.980003  67.160004  67.680000  67.680000   \n",
       "21  2019-08-29  68.300003  68.669998  68.089996  68.430000  68.430000   \n",
       "22  2019-08-30  68.610001  69.080002  68.059998  68.480003  68.480003   \n",
       "\n",
       "      Volume  \n",
       "0   13104600  \n",
       "1   17132800  \n",
       "2   21376700  \n",
       "3   19080900  \n",
       "4   12282400  \n",
       "5   15231100  \n",
       "6   14304100  \n",
       "7   13686600  \n",
       "8    8668400  \n",
       "9   12403300  \n",
       "10  18114400  \n",
       "11  12874400  \n",
       "12  12649000  \n",
       "13  10032800  \n",
       "14   9743500  \n",
       "15  10134200  \n",
       "16   8972000  \n",
       "17  15371900  \n",
       "18   7343900  \n",
       "19   9490900  \n",
       "20   9647400  \n",
       "21   9004100  \n",
       "22   9180800  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the real stock price for February 1st 2012 - \n",
    "# January 31st 2017\n",
    "\n",
    "dataset_test = pd.read_csv('dataset_test.csv')\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "real_stock_price.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75.040001],\n",
       "       [73.739998],\n",
       "       [72.610001],\n",
       "       [70.779999],\n",
       "       [70.290001],\n",
       "       [69.860001],\n",
       "       [70.849998],\n",
       "       [72.129997],\n",
       "       [70.059998],\n",
       "       [69.269997],\n",
       "       [69.07    ],\n",
       "       [67.459999],\n",
       "       [67.779999],\n",
       "       [68.970001],\n",
       "       [69.300003],\n",
       "       [69.959999],\n",
       "       [69.910004],\n",
       "       [68.82    ],\n",
       "       [68.120003],\n",
       "       [68.129997],\n",
       "       [67.529999],\n",
       "       [68.300003],\n",
       "       [68.610001]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_stock_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of 2017\n",
    "\n",
    "# axis = 0 means concatenate the lines (i.e. vertical axis)\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2540"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_total.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the difference in the length of the first two gives us \n",
    "# the first day in 2017, and we need to go back 60 days to get the necessary range\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 120:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we did not use iloc from panda so lets reshape the numpy array for \n",
    "# compatibility: i.e. all the values from input lines to be stacked in one \n",
    "# column. The -1 means that the numpy has no knowledge of how the \n",
    "# values were stored in lines. The 1 means we want to them in one \n",
    "# column.\n",
    "\n",
    "inputs = inputs.reshape(-1,1) \n",
    "\n",
    "# apply the feature scaler\n",
    "inputs = sc.transform(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For each price in Jan. 2017 we need the **immediate 60 values** before it. \n",
    "2. We have 21 prices in January;\n",
    "3. We need a numpy 3D array of 60 prices (columns) times 21 days (rows) times 1 dependent variable \n",
    "4. We dont need y_test. That is what we are trying to compute!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of 2017\n",
    "X_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first 60 from inputs are from training set; start \n",
    "# from 60 and get the extra 20, i.e. up to 80\n",
    "for i in range(120, 143): \n",
    "    X_test.append(inputs[i-120:i, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test) # not 3D structure yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 3D structure\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to inverse the scaling to get meaningful predicted stock price # outputs\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price) \n",
    "predicted_stock_price.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Exxon Mobil Stock Price')\n",
    "\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Exxon Mobil Stock Price')\n",
    "\n",
    "plt.title('Exxon Mobil Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Exxon Mobil Stock Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue line shows the trend of the stock for the month of January 2017. \n",
    "\n",
    "Some observations:\n",
    "- The prediction lags behind the actual price curve because the model cannot react to fast non-linear changes. Spikes are examples of fast non-linear changes\n",
    "- Model reacts pretty well to smooth changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the RMSE\n",
    "\n",
    "If we need to compute the RMSE for our Stock Price Prediction problem, we use the real stock price and predicted stock price as shown.\n",
    "\n",
    "Then consider dividing this RMSE by the range of the Google Stock Price values of January 2017 to get a relative error, as opposed to an absolute error. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = math.sqrt( mean_squared_error( real_stock_price[0:21,:], predicted_stock_price))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new data need to be placed in the same order/format  as in the case of the training/test sets.\n",
    "\n",
    "1. Getting more training data: we trained our model on the past 5 years of the  Google Stock Price but it would be even better to train it on the past 10 years.\n",
    "\n",
    "2. Increasing the number of time steps: the model remembered the stock price from the 60 previous financial days to predict the stock price of the next day. Thats because we chose a number of 60 time steps (3 months). You could try to increase the number of time steps, by choosing for example 120 time steps (6 months).\n",
    "\n",
    "3. Adding some other indicators: if you have the financial instinct that the stock price of some other companies might be correlated to the one of Google, you could add this other stock price as a new indicator in the training data.\n",
    "\n",
    "4. Adding more LSTM layers: we built a RNN with four LSTM layers but you could try with even more.\n",
    "\n",
    "5. Adding more neurons in the LSTM layers: we highlighted the fact that we needed a high number of neurons in the LSTM layers to respond better to the complexity of the problem and we chose to include 50 neurons in each of our 4 LSTM layers. You could try an architecture with even more neurons in each of the 4 (or more) LSTM layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the RNN\n",
    "\n",
    "Parameter Tuning on the RNN model: we are dealing with a Regression problem because we predict a continuous outcome.\n",
    "\n",
    "**Tip**: replace: scoring = 'accuracy' by scoring = 'neg_mean_squared_error' in the GridSearchCV class parameters as we did in the ANN case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size': [25, 32], 'epochs': [100, 500], 'optimizer': ['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'neg_mean_squared_error', cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = grid_search.best_score_\n",
    "best_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
